{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4749960c-975f-4173-8c0f-15e6b081e9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3311c4cc-170d-4fe3-b539-13aa8d67dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_travel = pd.read_csv('./shinkansen_travel_data/travel_data_train.csv')\n",
    "train_survey = pd.read_csv('./shinkansen_travel_data/survey_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ad4a67-8c99-4afd-abe2-07288ca69688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    # replace NaN with mean/mode for numerical and categoriacal\n",
    "    for col in data.select_dtypes(include=['number']).columns:\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "    for col in data.select_dtypes(include=['object']).columns:\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "    # create binary columns for each categorical option\n",
    "    data = pd.get_dummies(\n",
    "        data=data, \n",
    "        columns=list(data.select_dtypes(include=['object']).columns)).astype(int)\n",
    "    data.drop(['ID'],inplace=True, axis=1)\n",
    "    return data\n",
    "\n",
    "def concatenate(df1,df2):\n",
    "    return pd.concat([df1, df2], axis=1)\n",
    "\n",
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "def drop_highly_correlated(data, threshold=0.7):\n",
    "    correlation_matrix = data.corr().abs()\n",
    "    upper_triangle = correlation_matrix.where(\n",
    "        np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    highly_correlated_columns = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    data = data.drop(columns=highly_correlated_columns)\n",
    "    return data\n",
    "\n",
    "def correlation_matrix_plot(data):\n",
    "    correlation_matrix = data.corr()\n",
    "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        correlation_matrix, \n",
    "        mask=mask, \n",
    "        annot=True,\n",
    "        cmap=\"coolwarm\",\n",
    "        vmax=1, \n",
    "        vmin=-1, \n",
    "        center=0,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"shrink\": 0.75}\n",
    "    )\n",
    "    plt.title(\"Correlation Matrix (Lower Triangle)\")\n",
    "    plt.show()\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_test):\n",
    "    # add constant (i.e beta_0 intercept term)\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    X_test = sm.add_constant(X_test)\n",
    "    model = sm.Logit(y_train, X_train)\n",
    "    result = model.fit()\n",
    "    # print the summary\n",
    "    print(result.summary())\n",
    "    # predict\n",
    "    predictions = result.predict(X_test)\n",
    "    # convert probabilities to binary predictions (0/1)\n",
    "    binary_predictions = (predictions >= 0.5).astype(int)\n",
    "    return binary_predictions, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2bbe002-2b8c-4385-8eff-a08dae3d65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_travel, train_survey = clean_data(train_travel), clean_data(train_survey)\n",
    "train_data = concatenate(train_travel, train_survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fcd25d-b595-4052-a639-ebe6f0f72976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation_matrix_plot(train_travel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbff93f1-6557-4c68-a50d-4e64f7598b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_travel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ded393-9dda-4134-a383-d47ff1641f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94379, 98)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "columns_to_remove_outliers = [\n",
    "    'Travel_Distance', \n",
    "    'DepartureDelay_in_Mins',\n",
    "    'ArrivalDelay_in_Mins', \n",
    "    'Onboard_service_extremely poor', \n",
    "    'Onlinebooking_Ease_extremely poor', \n",
    "    'Platform_location_very inconvinient'\n",
    "]\n",
    "for column in columns_to_remove_outliers:\n",
    "    train_data = remove_outliers_iqr(train_data, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ce2fbb-6e23-4d4b-bb24-0cdf856cb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_data.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d65553-d3ae-49b6-b8c6-78264494d67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68605, 98)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f8a7ba-d09d-4dd4-bd86-73f2b63567c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68605, 66)\n"
     ]
    }
   ],
   "source": [
    "y = train_data['Overall_Experience']\n",
    "X = train_data.drop(['Overall_Experience'], axis=1)\n",
    "# drop highly correlated columns to reduce feature space\n",
    "X = drop_highly_correlated(X, threshold=0.5)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0df876b-8ad3-4fd9-84fb-d78d5a917bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the design matrix: 55\n",
      "Number of features: 66\n",
      "Duplicate Columns: []\n",
      "Constant Columns: ['Platform_location_very inconvinient', 'Online_support_extremely poor', 'Onlinebooking_Ease_extremely poor', 'Onboard_service_extremely poor', 'Checkin_service_extremely poor', 'Cleanliness_extremely poor', 'Online_boarding_extremely poor']\n",
      "(68605, 59)\n",
      "Remaining columns after dropping high VIF features: 30\n",
      "Rank of the updated design matrix: 30\n"
     ]
    }
   ],
   "source": [
    "rank = np.linalg.matrix_rank(X)\n",
    "print(f\"Rank of the design matrix: {rank}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "# checking for duplicate columns\n",
    "duplicate_columns = X.columns[X.columns.duplicated()]\n",
    "print(f\"Duplicate Columns: {duplicate_columns.tolist()}\")\n",
    "# checking for constant columns\n",
    "constant_columns = [col for col in X.columns if X[col].nunique() <= 1]\n",
    "print(f\"Constant Columns: {constant_columns}\")\n",
    "X = X.drop(columns=constant_columns)\n",
    "print(X.shape)\n",
    "\n",
    "# calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "# drop features with high VIF\n",
    "high_vif_features = vif_data[vif_data[\"VIF\"] > 10][\"Feature\"].tolist()\n",
    "X = X.drop(columns=high_vif_features)\n",
    "# check the updated shape and rank\n",
    "print(f\"Remaining columns after dropping high VIF features: {X.shape[1]}\")\n",
    "rank = np.linalg.matrix_rank(X)\n",
    "print(f\"Rank of the updated design matrix: {rank}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "300d203f-a3e0-4607-b597-93b768ea7690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.356659\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:     Overall_Experience   No. Observations:                54884\n",
      "Model:                          Logit   Df Residuals:                    54853\n",
      "Method:                           MLE   Df Model:                           30\n",
      "Date:                Fri, 01 Nov 2024   Pseudo R-squ.:                  0.4778\n",
      "Time:                        17:06:52   Log-Likelihood:                -19575.\n",
      "converged:                       True   LL-Null:                       -37483.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "=====================================================================================================\n",
      "                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "const                                -2.4603      0.081    -30.229      0.000      -2.620      -2.301\n",
      "Age                                  -0.0026      0.001     -2.891      0.004      -0.004      -0.001\n",
      "Travel_Distance                   -5.494e-05   1.47e-05     -3.731      0.000   -8.38e-05   -2.61e-05\n",
      "DepartureDelay_in_Mins                0.0053      0.003      1.805      0.071      -0.000       0.011\n",
      "ArrivalDelay_in_Mins                 -0.0568      0.005    -11.736      0.000      -0.066      -0.047\n",
      "Gender_Female                         1.0398      0.026     39.377      0.000       0.988       1.092\n",
      "CustomerType_Loyal Customer           1.9926      0.039     51.192      0.000       1.916       2.069\n",
      "TypeTravel_Business travel            1.2307      0.031     40.248      0.000       1.171       1.291\n",
      "Seat_Class_Green Car                  0.0017      0.026      0.068      0.946      -0.048       0.052\n",
      "Platform_location_Convinient         -0.1634      0.032     -5.101      0.000      -0.226      -0.101\n",
      "Platform_location_manageable         -0.2033      0.031     -6.516      0.000      -0.264      -0.142\n",
      "Onboard_entertainment_acceptable     -0.4951      0.041    -12.221      0.000      -0.574      -0.416\n",
      "Onboard_entertainment_excellent       3.7963      0.058     65.518      0.000       3.683       3.910\n",
      "Onboard_entertainment_good            1.5468      0.036     42.865      0.000       1.476       1.618\n",
      "Onboard_entertainment_poor           -0.2880      0.049     -5.856      0.000      -0.384      -0.192\n",
      "Online_support_acceptable            -0.2174      0.048     -4.531      0.000      -0.311      -0.123\n",
      "Online_support_excellent              0.9309      0.051     18.350      0.000       0.831       1.030\n",
      "Online_support_good                   0.5919      0.045     13.294      0.000       0.505       0.679\n",
      "Online_support_need improvement       0.0635      0.049      1.290      0.197      -0.033       0.160\n",
      "Onlinebooking_Ease_excellent          0.0705      0.043      1.648      0.099      -0.013       0.154\n",
      "Onboard_service_acceptable           -0.8236      0.046    -18.070      0.000      -0.913      -0.734\n",
      "Onboard_service_good                 -0.3975      0.041     -9.700      0.000      -0.478      -0.317\n",
      "Onboard_service_need improvement     -1.4036      0.056    -25.243      0.000      -1.513      -1.295\n",
      "Onboard_service_poor                 -1.4305      0.060    -23.849      0.000      -1.548      -1.313\n",
      "Baggage_handling_acceptable          -0.9896      0.047    -21.070      0.000      -1.082      -0.898\n",
      "Baggage_handling_good                -0.3103      0.037     -8.313      0.000      -0.383      -0.237\n",
      "Baggage_handling_need improvement    -0.9687      0.055    -17.737      0.000      -1.076      -0.862\n",
      "Baggage_handling_poor                -0.8583      0.065    -13.126      0.000      -0.986      -0.730\n",
      "Cleanliness_acceptable               -0.6983      0.044    -15.803      0.000      -0.785      -0.612\n",
      "Cleanliness_good                     -0.1586      0.035     -4.584      0.000      -0.226      -0.091\n",
      "Cleanliness_poor                     -0.2649      0.063     -4.192      0.000      -0.389      -0.141\n",
      "=====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# call log reg function from statsmodel\n",
    "y_preds, model = logistic_regression(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb8f9dcf-5dba-46a4-b1fe-bfa95abc43f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8449\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82      5856\n",
      "           1       0.87      0.86      0.86      7865\n",
      "\n",
      "    accuracy                           0.84     13721\n",
      "   macro avg       0.84      0.84      0.84     13721\n",
      "weighted avg       0.85      0.84      0.85     13721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "accuracy = accuracy_score(y_test, y_preds)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "# classification report: will make this a plot\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8a2bc0-6999-4e9f-8514-2094f9daf341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Accuracy: 0.82\n",
      "Gaussian Naive Bayes Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# fit Bernoulli Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "# pred and eval\n",
    "y_pred = bnb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Bernoulli Naive Bayes Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Gausiian NB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "# predict and evaluate\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Gaussian Naive Bayes Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c116aa-e631-4cb4-8fda-ad0651fc2a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
